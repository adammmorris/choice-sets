ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b <- sqrt((se.estimate ^ 2) / (ss.sdo * tol.sdo))
t.stat <- b / se.b
2 * pt(t.stat, N - J - 1, lower.tail = F)
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# That semi-partial correlation is a measure of the relationship between
# affirmative action opposition and education, controlling for the
# effect of SDO on education.
# It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(MASS)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(ez)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
200 * .7
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
rm(list=ls())
N <- 361 # sample size
J <- 7 # number of predictors
ss.reg <- 59.69 # sum of squares of regression model
ss.res <- 344.25 # sum of squares of residuals
ms.reg <- ss.reg / J # mean-square regression
ms.res <- ss.res / (N - J - 1) # mean-square residuals
## 3a.
# What % of the variation in opposition to affirmative action can be explained
# by the other variables?
# The % of variance explained by all of them is R-squared, which is
# SS-reg / (SS-reg + SS-res), or...
rsq <- ss.reg / (ss.reg + ss.res) # .15
# The % of variance that can be explained by each predictor (NOT controlling
# for other variables) is the square of the zero-order correlations, or...
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
# in the order on the homework:
# .055 .072 .0017 .0083 .019 .0059 .030
# The % of variance that can be explained by each predictor (controlling for the
# effects of the other predictors on this predictor) is the square of the semi-partial correlation
# between opposition to affirmative action and the predictor (available in the output), or..
c(.179, .178, -.029, .121, .0884, -.0347, .105) ^ 2
# in the order on the homework:
# .032 .032 .00084 .015 .0078 .0012 .011
f.stat <- ms.reg / ms.res
# and get the p value by using the F distribution function...
pf(f.stat, J, N - J - 1, lower.tail = F)
rsq.adj <- 1 - (1 - rsq) * (N - 1) / (N - J - 1) # .13
var.res <- ss.res / (N - J - 1) # .98
.0884 ^ 2 # .0078
b.educ <- .143 * 1.059 / 1.618
# then, calculate a t statistic by t(N - J - 1) = b / std-error(b), pulling std-error(b) from the
# output, or...
t.stat.educ <- b.educ / .038
# finally, get the (2-tailed) p value by looking up this value in the t distribution
2 * pt(t.stat.educ, N - J - 1, lower.tail = FALSE) # .014
# p < .05; opposition to affirmative action can be predicted by education at an above-chance level
## 3g.
# Same explanation as above.
b.sdo <- .115 * 1.059 / .114
# As it's not in the output, this time we need to calculate the standard error of the unstandarized
# coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate.sdo <- sqrt(ss.res / N) # .98
se.estimate.sdo <- sqrt(ss.res / N) # .98
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b.sdo <- sqrt((se.estimate.sdo ^ 2) / (ss.sdo * tol.sdo)) # .49
t.stat.sdo <- b.sdo / se.b.sdo # 2.18
2 * pt(t.stat.sdo, N - J - 1, lower.tail = FALSE) # .030
# p < .05; opposition to affirmative action can be predicted by SDO at an above-chance level
## 3h.
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# This semi-partial correlation is a measure of the relationship between affirmative action
# opposition and education, controlling for the effect of SDO on education. It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2) # .13
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
install.packages("BiasedUrn")
setwd("~/Me/Psychology/Projects/choicesets/with_sam")
require(dplyr)
require(ggplot2)
require(lme4)
require(lmerTest)
require(mlogit)
require(stringdist)
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(colour = "black"),
axis.text=element_text(size=20, colour = "black"), axis.title=element_text(size=18, face = "bold"), axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"), legend.text = element_text(size = 20), plot.title = element_text(size = 26, face = "bold", vjust = 1))
setwd("~/Me/Psychology/Projects/choicesets/with_sam")
## Setup
getIndex = function(x, list) {
y = numeric(length(x))
for (j in 1:length(x)) {
if (any(list %in% x[j])) {
y[j] = which(list %in% x[j])
} else {
y[j] = NA
}
}
return(y)
}
as.string.vector = function(x) {
temp = strsplit(substr(x,2,nchar(x)-1), split=",")[[1]]
return(substr(temp, 2, nchar(temp) - 1))
}
as.numeric.vector = function(x) {
return(as.numeric(strsplit(substr(x,2,nchar(x)-1), split=",")[[1]]))
}
numWords = 21;
pointsPerCent = 10;
nTrials = 112;
path = 'data/cs_wg_v3_poss/real1/'
df.demo = read.csv(paste0(path, 'demo.csv'), stringsAsFactors = F) %>% arrange(subject) %>% mutate(total_time_real = total_time / 60000)
df.words.raw = read.csv(paste0(path, 'words.csv'), stringsAsFactors = F) %>% arrange(subject, word_ind)
df.s1.raw = read.csv(paste0(path, 's1.csv'), stringsAsFactors = F) %>% arrange(subject)
df.s2.raw = read.csv(paste0(path, 'poss.csv'), stringsAsFactors = F) %>% arrange(subject)
subjlist = df.demo$subject
## Fix DFs
# drop anyone who didn't finish
df.s1 = df.s1.raw %>% filter(subject %in% subjlist) %>% mutate(correct_word = ain(toupper(resp), word, maxDist = 2), correct_val = resp2 == value)
df.s2 = df.s2.raw %>% filter(subject %in% subjlist)
df.words = df.words.raw %>% mutate(doubled = ifelse(is.na(lead(word)), FALSE, word == lead(word) & subject == lead(subject))) %>%
filter(doubled == FALSE & subject %in% subjlist) %>%
mutate(high_val = value > 5, numChosen = 0)
# get numChosen & cors
df.s1.subjword = df.s1 %>% group_by(subject, word) %>% summarize(numChosen = sum(choice == 0))
for (i in 1:nrow(df.words)) {
subjword_rows = df.s1.subjword$subject == df.words$subject[i] & df.s1.subjword$word == df.words$word[i]
df.words$numChosen[i] = ifelse(any(subjword_rows), df.s1.subjword$numChosen[subjword_rows], NA)
}
df.cors = df.words %>% group_by(subject) %>% filter(value %in% c(0,10)) %>% summarize(cors = cor(numChosen, value))
# get pctCorrects
df.s1.subj = df.s1 %>% group_by(subject) %>% summarize(pctCorrect_words = mean(correct_word), pctCorrect_val = mean(correct_val, na.rm = T), numTrials = n())
# Mutate df.s2
df.s2.prac = df.s2 %>% filter(practice == 1)
df.s2 = df.s2 %>% filter(practice == 0)
df.s2$prompt = toupper(df.s2$prompt)
df.s2$choice_real = NULL
df.s2$choice_real_ind = NULL
df.s2$s1_value = NULL
df.s2$s1_exposures = NULL
df.s2$s1_chosen = NULL
df.s2$seen_memory = NULL
df.s2$seen_poss = NULL
for (i in 1:nrow(df.s2)) {
subj.name = df.s2$subject[i]
if (i == 1 || subj.name != df.s2$subject[i - 1]) {
seen_memory = FALSE
seen_poss = F
}
if (df.s2$modality[i] == 'should' || df.s2$modality[i] == 'ought') {
seen_memory = TRUE
}
if (df.s2$modality[i] == 'possible') {
seen_poss = TRUE
}
wordlist = (df.words %>% filter(subject == subj.name))$word
c = df.s2$prompt[i]
creal = wordlist[amatch(c, wordlist, maxDist = 2)]
cind = getIndex(creal, wordlist)
word_rows = subj.name == df.words$subject & creal == df.words$word
s1_val = ifelse(is.na(cind), -1, df.words$value[word_rows])
df.s2$choice_real[i] = creal
df.s2$choice_real_ind[i] = cind
df.s2$s1_value[i] = s1_val
df.s2$s1_exposures[i] = ifelse(is.na(cind) | s1_val == -1, NA, df.words$exposures[word_rows])
df.s2$s1_chosen[i] = ifelse(is.na(cind) | s1_val == -1, NA, df.words$numChosen[word_rows])
df.s2$seen_memory[i] = seen_memory
df.s2$seen_poss[i] = seen_poss
}
df.s2$s1_value = factor(df.s2$s1_value, levels = c(-1, 5, 0, 1, 9, 10), labels = c('absent', 'grey', 'low1', 'low2', 'high1', 'high2'))
levels(df.s2$s1_value) = list(low=c('low1','low2'), high=c('high1','high2'), absent='absent')
#df.s2 = df.s2 %>% mutate(s2_subj_ind = as.numeric(as.factor(subject)))
df.s2.prac.subj = df.s2.prac %>% group_by(subject) %>%
summarize(correct = mean(correct))
df.s2.subj = df.s2 %>% group_by(subject) %>%
summarize(pctNA = mean(choice == -1))
## Compute exclusion
# Exclude if any of these: cor in s1 < .75, pctCorrect_words < .75, pctCorrect_pts < .75, pctCorrect_prac < .75, pctNA > .2
include_rows = NULL
include_names = NULL
for (subj in 1:nrow(df.demo)) {
subj.name = df.demo$subject[subj]
df.s1.subj.temp = df.s1.subj %>% filter(subject == subj.name)
df.s2.subj.temp = df.s2.subj %>% filter(subject == subj.name)
df.cors.temp = df.cors %>% filter(subject == subj.name)
if (df.s1.subj.temp$pctCorrect_words < .75 || df.cors.temp$cors < .75 || df.s1.subj.temp$numTrials != nTrials || df.s2.subj.temp$pctNA > .2) {
include_rows[subj] = FALSE
} else {
include_rows[subj] = TRUE
include_names = c(include_names, subj.name)
}
}
df.s2.raw = read.csv(paste0(path, 's2.csv'), stringsAsFactors = F) %>% arrange(subject)
subjlist = df.demo$subject
## Fix DFs
# drop anyone who didn't finish
df.s1 = df.s1.raw %>% filter(subject %in% subjlist) %>% mutate(correct_word = ain(toupper(resp), word, maxDist = 2), correct_val = resp2 == value)
df.s2 = df.s2.raw %>% filter(subject %in% subjlist)
df.words = df.words.raw %>% mutate(doubled = ifelse(is.na(lead(word)), FALSE, word == lead(word) & subject == lead(subject))) %>%
filter(doubled == FALSE & subject %in% subjlist) %>%
mutate(high_val = value > 5, numChosen = 0)
# get numChosen & cors
df.s1.subjword = df.s1 %>% group_by(subject, word) %>% summarize(numChosen = sum(choice == 0))
for (i in 1:nrow(df.words)) {
subjword_rows = df.s1.subjword$subject == df.words$subject[i] & df.s1.subjword$word == df.words$word[i]
df.words$numChosen[i] = ifelse(any(subjword_rows), df.s1.subjword$numChosen[subjword_rows], NA)
}
df.cors = df.words %>% group_by(subject) %>% filter(value %in% c(0,10)) %>% summarize(cors = cor(numChosen, value))
# get pctCorrects
df.s1.subj = df.s1 %>% group_by(subject) %>% summarize(pctCorrect_words = mean(correct_word), pctCorrect_val = mean(correct_val, na.rm = T), numTrials = n())
# Mutate df.s2
df.s2.prac = df.s2 %>% filter(practice == 1)
df.s2 = df.s2 %>% filter(practice == 0)
df.s2$prompt = toupper(df.s2$prompt)
df.s2$choice_real = NULL
df.s2$choice_real_ind = NULL
df.s2$s1_value = NULL
df.s2$s1_exposures = NULL
df.s2$s1_chosen = NULL
df.s2$seen_memory = NULL
df.s2$seen_poss = NULL
for (i in 1:nrow(df.s2)) {
subj.name = df.s2$subject[i]
if (i == 1 || subj.name != df.s2$subject[i - 1]) {
seen_memory = FALSE
seen_poss = F
}
if (df.s2$modality[i] == 'should' || df.s2$modality[i] == 'ought') {
seen_memory = TRUE
}
if (df.s2$modality[i] == 'possible') {
seen_poss = TRUE
}
wordlist = (df.words %>% filter(subject == subj.name))$word
c = df.s2$prompt[i]
creal = wordlist[amatch(c, wordlist, maxDist = 2)]
cind = getIndex(creal, wordlist)
word_rows = subj.name == df.words$subject & creal == df.words$word
s1_val = ifelse(is.na(cind), -1, df.words$value[word_rows])
df.s2$choice_real[i] = creal
df.s2$choice_real_ind[i] = cind
df.s2$s1_value[i] = s1_val
df.s2$s1_exposures[i] = ifelse(is.na(cind) | s1_val == -1, NA, df.words$exposures[word_rows])
df.s2$s1_chosen[i] = ifelse(is.na(cind) | s1_val == -1, NA, df.words$numChosen[word_rows])
df.s2$seen_memory[i] = seen_memory
df.s2$seen_poss[i] = seen_poss
}
df.s2$s1_value = factor(df.s2$s1_value, levels = c(-1, 5, 0, 1, 9, 10), labels = c('absent', 'grey', 'low1', 'low2', 'high1', 'high2'))
levels(df.s2$s1_value) = list(low=c('low1','low2'), high=c('high1','high2'), absent='absent')
#df.s2 = df.s2 %>% mutate(s2_subj_ind = as.numeric(as.factor(subject)))
df.s2.prac.subj = df.s2.prac %>% group_by(subject) %>%
summarize(correct = mean(correct))
df.s2.subj = df.s2 %>% group_by(subject) %>%
summarize(pctNA = mean(choice == -1))
## Compute exclusion
# Exclude if any of these: cor in s1 < .75, pctCorrect_words < .75, pctCorrect_pts < .75, pctCorrect_prac < .75, pctNA > .2
include_rows = NULL
include_names = NULL
for (subj in 1:nrow(df.demo)) {
subj.name = df.demo$subject[subj]
df.s1.subj.temp = df.s1.subj %>% filter(subject == subj.name)
df.s2.subj.temp = df.s2.subj %>% filter(subject == subj.name)
df.cors.temp = df.cors %>% filter(subject == subj.name)
if (df.s1.subj.temp$pctCorrect_words < .75 || df.cors.temp$cors < .75 || df.s1.subj.temp$numTrials != nTrials || df.s2.subj.temp$pctNA > .2) {
include_rows[subj] = FALSE
} else {
include_rows[subj] = TRUE
include_names = c(include_names, subj.name)
}
}
se = function(x) {return(sd(x) / sqrt(length(x)))}
dodge <- position_dodge(width=0.9)
df.poss = df.s2 %>% filter(choice != -1 & modality == 'possible' & subject %in% include_names & !seen_memory) %>%
mutate(choice = ifelse(choice == 1, 0, 1))
df.halfway = df.poss %>% group_by(subject, cond, s1_value) %>%
summarize(choice = mean(choice))
df.collapsed = df.halfway %>% group_by(cond, s1_value) %>%
summarize(choice.mean = mean(choice), choice.se = se(choice))
ggplot(df.collapsed, aes(x = s1_value, y = choice.mean, group = cond, fill = cond)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymax = choice.mean + choice.se, ymin = choice.mean - choice.se), width = .5, position = dodge) +
xlab('') + ylab('')
View(df.s1.subj)
se = function(x) {return(sd(x) / sqrt(length(x)))}
dodge <- position_dodge(width=0.9)
df.poss = df.s2 %>% filter(choice != -1 & modality == 'possible' & subject %in% include_names) %>%
mutate(choice = ifelse(choice == 1, 0, 1))
df.halfway = df.poss %>% group_by(subject, cond, s1_value) %>%
summarize(choice = mean(choice))
df.collapsed = df.halfway %>% group_by(cond, s1_value) %>%
summarize(choice.mean = mean(choice), choice.se = se(choice))
ggplot(df.collapsed, aes(x = s1_value, y = choice.mean, group = cond, fill = cond)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymax = choice.mean + choice.se, ymin = choice.mean - choice.se), width = .5, position = dodge) +
xlab('') + ylab('')
include_rows = NULL
include_names = NULL
for (subj in 1:nrow(df.demo)) {
subj.name = df.demo$subject[subj]
df.s1.subj.temp = df.s1.subj %>% filter(subject == subj.name)
df.s2.subj.temp = df.s2.subj %>% filter(subject == subj.name)
df.cors.temp = df.cors %>% filter(subject == subj.name)
if (df.s1.subj.temp$pctCorrect_words < .75 || df.cors.temp$cors < .75 || df.s1.subj.temp$numTrials != nTrials || df.s2.subj.temp$pctNA > .2) {
include_rows[subj] = FALSE
} else {
include_rows[subj] = TRUE
include_names = c(include_names, subj.name)
}
}
df.s1.subj.temp
nTrials
nTrials = 120;
include_rows = NULL
include_names = NULL
for (subj in 1:nrow(df.demo)) {
subj.name = df.demo$subject[subj]
df.s1.subj.temp = df.s1.subj %>% filter(subject == subj.name)
df.s2.subj.temp = df.s2.subj %>% filter(subject == subj.name)
df.cors.temp = df.cors %>% filter(subject == subj.name)
if (df.s1.subj.temp$pctCorrect_words < .75 || df.cors.temp$cors < .75 || df.s1.subj.temp$numTrials != nTrials || df.s2.subj.temp$pctNA > .2) {
include_rows[subj] = FALSE
} else {
include_rows[subj] = TRUE
include_names = c(include_names, subj.name)
}
}
se = function(x) {return(sd(x) / sqrt(length(x)))}
dodge <- position_dodge(width=0.9)
df.poss = df.s2 %>% filter(choice != -1 & modality == 'possible' & subject %in% include_names) %>%
mutate(choice = ifelse(choice == 1, 0, 1))
df.halfway = df.poss %>% group_by(subject, cond, s1_value) %>%
summarize(choice = mean(choice))
df.collapsed = df.halfway %>% group_by(cond, s1_value) %>%
summarize(choice.mean = mean(choice), choice.se = se(choice))
ggplot(df.collapsed, aes(x = s1_value, y = choice.mean, group = cond, fill = cond)) +
geom_bar(stat = "identity", position = dodge) +
geom_errorbar(aes(ymax = choice.mean + choice.se, ymin = choice.mean - choice.se), width = .5, position = dodge) +
xlab('') + ylab('')
m.simple = lmer(choice ~ cond * s1_value + (1 | subject), data = df.halfway %>% filter(s1_value %in% c('low', 'high')))
summary(m.simple)
m.simple = lmer(choice ~ cond * s1_value + (1 + s1_value | subject), data = df.halfway %>% filter(s1_value %in% c('low', 'high')))
summary(m.simple)
df.halfway
df.halfway
m = glmer(choice ~ cond * s1_value + (1 | subject) + (0 + s1_value | subject) + (1 + cond * s1_value | prompt),
data = df.s2 %>% filter(choice != -1 & modality == 'possible' & s1_value %in% c('low', 'high') & subject %in% include_names),
family = binomial)
View(df.s2)
m = glmer(choice ~ cond * s1_value + (1 | subject) + (0 + s1_value | subject) + (1 + cond * s1_value | prompt),
data = df.s2 %>% filter(choice != -1 & modality == 'possible' & s1_value %in% c('low', 'high') & subject %in% include_names),
family = binomial)
summary(m)
m = glmer(choice ~ cond * s1_value + (1 + s1_value | subject),
data = df.s2 %>% filter(choice != -1 & modality == 'possible' & s1_value %in% c('low', 'high') & subject %in% include_names),
family = binomial)
summary(m)
## Get bonuses
df.demo = df.demo %>% mutate(bonus = round(s1_bonus / (pointsPerCent * 100), 2))
m = glmer(choice ~ cond * s1_value + (1 | subject),
data = df.s2 %>% filter(choice != -1 & modality == 'possible' & s1_value %in% c('low', 'high') & subject %in% include_names),
family = binomial)
summary(m)
df.halfway
m = glmer(choice ~ cond * s1_value + (1 | subject),
data = df.poss %>% filter(s1_value %in% c('low', 'high')),
family = binomial)
summary(m)
View(df.poss)
df.halfway
require(ez)
?ezANOVA
data.frame(df.halwfay)
data.frame(df.halfway)
ezANOVA(data.frame(df.halfway %>% filter(s1_value %in% c('low', 'high'))), choice, s1_value, between = cond)
ezANOVA(data.frame(df.halfway %>% filter(s1_value %in% c('low', 'high'))), choice, within = s1_value, between = cond)
ezANOVA(data.frame(df.halfway %>% filter(s1_value %in% c('low', 'high'))), choice, wid = subject, within = s1_value, between = cond)
