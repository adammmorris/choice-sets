var.res <- ss.res / (N - J - 1)
.0884 ^ 2
b <- .143 * 1.618 / 1.059
t.stat <- b / .038
?pt
2 * pt(t.stat, N - J - 1)
pt(t.stat, N - J - 1)
2 * pt(t.stat, N - J - 1, lower.tail = F)
.114 ^ 2
.073 ^ 2
.073 ^ 2 * N / (N - 1)
.073 ^ 2 * (N - 1) / N
t.stat <- b / se.b
b <- .115 * .114 / 1.059
# We need to calculate the standard error of the unstandarized coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate <- sqrt(ss.res / N)
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b <- sqrt((se.estimate ^ 2) / (ss.sdo * tol.sdo))
t.stat <- b / se.b
2 * pt(t.stat, N - J - 1, lower.tail = F)
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# That semi-partial correlation is a measure of the relationship between
# affirmative action opposition and education, controlling for the
# effect of SDO on education.
# It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(MASS)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
require(ez)
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 125
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
200 * .7
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
rm(list=ls())
N <- 361 # sample size
J <- 7 # number of predictors
ss.reg <- 59.69 # sum of squares of regression model
ss.res <- 344.25 # sum of squares of residuals
ms.reg <- ss.reg / J # mean-square regression
ms.res <- ss.res / (N - J - 1) # mean-square residuals
## 3a.
# What % of the variation in opposition to affirmative action can be explained
# by the other variables?
# The % of variance explained by all of them is R-squared, which is
# SS-reg / (SS-reg + SS-res), or...
rsq <- ss.reg / (ss.reg + ss.res) # .15
# The % of variance that can be explained by each predictor (NOT controlling
# for other variables) is the square of the zero-order correlations, or...
c(.235, .268, -.041, .091, .138, .077, .173) ^ 2
# in the order on the homework:
# .055 .072 .0017 .0083 .019 .0059 .030
# The % of variance that can be explained by each predictor (controlling for the
# effects of the other predictors on this predictor) is the square of the semi-partial correlation
# between opposition to affirmative action and the predictor (available in the output), or..
c(.179, .178, -.029, .121, .0884, -.0347, .105) ^ 2
# in the order on the homework:
# .032 .032 .00084 .015 .0078 .0012 .011
f.stat <- ms.reg / ms.res
# and get the p value by using the F distribution function...
pf(f.stat, J, N - J - 1, lower.tail = F)
rsq.adj <- 1 - (1 - rsq) * (N - 1) / (N - J - 1) # .13
var.res <- ss.res / (N - J - 1) # .98
.0884 ^ 2 # .0078
b.educ <- .143 * 1.059 / 1.618
# then, calculate a t statistic by t(N - J - 1) = b / std-error(b), pulling std-error(b) from the
# output, or...
t.stat.educ <- b.educ / .038
# finally, get the (2-tailed) p value by looking up this value in the t distribution
2 * pt(t.stat.educ, N - J - 1, lower.tail = FALSE) # .014
# p < .05; opposition to affirmative action can be predicted by education at an above-chance level
## 3g.
# Same explanation as above.
b.sdo <- .115 * 1.059 / .114
# As it's not in the output, this time we need to calculate the standard error of the unstandarized
# coefficient by:
# std-error-b <- sqrt(std-error-estimate ^ 2 / (ss-SDO * (1 - coef-of-multicollinearity)))
se.estimate.sdo <- sqrt(ss.res / N) # .98
se.estimate.sdo <- sqrt(ss.res / N) # .98
# to get the ss-SDO, we square the standard deviation of SDO (to get variance)
# and then multiply by N. (We're assuming that SPSS isn't reporting the
# unbiased estimate of population standard deviation.)
ss.sdo <- (.114 ^ 2) * N
# note that (1 - coef-of-multicollinearity(sdo)) = tolerance(sdo),
# which is given
tol.sdo <- .843
# so:
se.b.sdo <- sqrt((se.estimate.sdo ^ 2) / (ss.sdo * tol.sdo)) # .49
t.stat.sdo <- b.sdo / se.b.sdo # 2.18
2 * pt(t.stat.sdo, N - J - 1, lower.tail = FALSE) # .030
# p < .05; opposition to affirmative action can be predicted by SDO at an above-chance level
## 3h.
cor.aa.ed <- .091
cor.aa.sdo <- .173
cor.ed.sdo <- -.228
# This semi-partial correlation is a measure of the relationship between affirmative action
# opposition and education, controlling for the effect of SDO on education. It is calculated by:
spcor.aa.ed <- (cor.aa.ed - cor.aa.sdo * cor.ed.sdo) / sqrt(1 - cor.ed.sdo ^ 2) # .13
# Power analysis
# (This is with no interaction - within-subjects one-way anova)
mean_yes = .5;
mean_no = .4;
sd = .35;
cor = .3;
cov = cor * (sd ^ 2);
#mean2a = .5;
#mean2b = .5;
n = 140
nTests = 1000
success = vector(mode = "logical", length = nTests)
for (i in 1:nTests) {
subjects <- mvrnorm(n, c(mean_yes, mean_no, mean_no),
matrix(c(sd ^ 2, cov, cov,
cov, sd ^ 2, cov,
cov, cov, sd ^ 2), nrow = 3))
my.df <- data.frame(subject = as.factor(rep(1:n, 3)),
condition = as.factor(rep(1:3, each = n)),
scr = as.vector(subjects))
fit <- ezANOVA(my.df, dv = scr, wid = subject, within = condition)
if (fit$ANOVA[1,5] < .05) {
success[i] = TRUE
}
}
mean(success)
install.packages("BiasedUrn")
# setup -------------------------------------------------------------------
require(dplyr)
require(ggplot2)
require(lme4)
require(lmerTest)
require(mlogit)
require(lattice)
require(stringdist)
theme_update(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(colour = "black"),
axis.text=element_text(size=20, colour = "black"), axis.title=element_text(size=18, face = "bold"), axis.title.x = element_text(vjust = 0),
legend.title = element_text(size = 24, face = "bold"), legend.text = element_text(size = 20), plot.title = element_text(size = 26, face = "bold", vjust = 1))
setwd("~/Me/Psychology/Projects/choicesets/git")
getIndex = function(x, list) {
y = numeric(length(x))
for (j in 1:length(x)) {
if (any(list %in% x[j])) {
y[j] = which(list %in% x[j])
} else {
y[j] = NA
}
}
return(y)
}
as.string.vector = function(x) {
temp = strsplit(substr(x,2,nchar(x)-1), split=",")[[1]]
return(substr(temp, 2, nchar(temp) - 1))
}
as.numeric.vector = function(x) {
return(as.numeric(strsplit(substr(x,2,nchar(x)-1), split=",")[[1]]))
}
runLogit = function(df) {
df$Choice = as.logical(df$Choice)
df$OptionID = factor(df$OptionID)
df = df %>% mutate(Trial_unique = paste(Subj, Trial, sep="_"))
df$Trial = factor(df$Trial)
df$Trial_unique = factor(df$Trial_unique)
df$Subj = factor(df$Subj)
df.m = mlogit.data(df, choice = "Choice", shape = "long", id.var = "Subj", alt.var = "OptionID", chid.var = "Trial_unique")
m = mlogit(Choice ~ MFval + MBval | -1, df.m, panel = T,
rpar = c(MFval = "n", MBval = "n"), correlation = F, halton = NA, R = 1000, tol = .001)
return(m)
}
se = function(x) {return(sd(x) / sqrt(length(x)))}
dodge <- position_dodge(width=0.9)
# import data -------------------------------------------------------------
versions = c('value1', 'value2', 'freq', 'confounded', 'stripped')
version = versions[3]
if (version == 'value1') {
numWords = 14;
numTrials = 112;
minNAs = 4;
path = 'data/value/v1/real2/'
pointsPerCent = 10;
pointsPerWord = 10; # for memory condition
type = 0; # 0 is value, 1 is freq, 2 is stripped
} else if (version == 'value2') {
numWords = 14;
numTrials = 112;
minNAs = 2;
path = 'data/value/v2/real1/'
pointsPerCent = 10;
pointsPerWord = 10; # for memory condition
type = 0;
} else if (version == 'freq') {
numWords = 14;
numTrials = 112;
minNAs = 4;
path = 'data/frequency/v1/real1/'
type = 1;
} else if (version == 'confounded') {
numWords = 14;
numTrials = 91;
minNAs = 4;
path = 'data/confounded/v1/real1/'
type = 0;
} else if (version == 'stripped') {
numWords = 14;
numTrials = 0;
minNAs = 1;
path = 'data/value/v3/real2/'
type = 2;
}
# Load data
df.demo = read.csv(paste0(path, 'demo.csv'), stringsAsFactors = F) %>% arrange(subject) %>% mutate(total_time_real = total_time / 60000)
df.words.raw = read.csv(paste0(path, 'words.csv'), stringsAsFactors = F) %>% arrange(subject, word_ind)
if (type != 2) {
df.s1.raw = read.csv(paste0(path, 's1.csv'), stringsAsFactors = F) %>% arrange(subject);
} else {
df.s1.raw = data.frame(subject = numeric(), resp = numeric(), word = numeric(), resp2 = numeric(), value = numeric(), alt = numeric(),
choice = numeric());
}
df.s2.raw = read.csv(paste0(path, 's2.csv'), stringsAsFactors = F) %>% arrange(subject, question_order)
subjlist = df.demo$subject
## words
df.words = df.words.raw %>%
mutate(doubled = ifelse(is.na(lead(word)), FALSE, word == lead(word) & subject == lead(subject))) %>%
filter(doubled == FALSE & subject %in% subjlist)
for (i in 1:nrow(df.words)) {
df.words$high_value[i] = ifelse(type == 1, df.words$exposures[i] > 8, df.words$value[i] > 5)
if (type == 2) { # stripped-down version
valuelist = (df.words %>% filter(subject == df.words$subject[i]))$value
df.words$high_value[i] = df.words$value[i] > median(valuelist)
}
}
## s1
df.s1 = df.s1.raw %>% filter(subject %in% subjlist) %>%
mutate(correct_word = ain(toupper(resp), word, maxDist = 2), correct_val = resp2 == value, word_chosen = ifelse(choice, alt, word))
df.s1.subj = df.s1 %>% group_by(subject) %>%
summarize(pctCorrect_words = mean(correct_word, na.rm = T), pctCorrect_val = ifelse(type == 1, 1, mean(correct_val, na.rm = T)),
numTrials = n())
## s2
df.s2 = df.s2.raw %>% filter(subject %in% subjlist)
df.s2$choice = toupper(df.s2$choice)
df.s2$scratch = gsub("[.]", ",", toupper(as.character(df.s2$scratch)))
df.s2$all_values = as.character(df.s2$all_values)
df.s2$rank_value = NULL
for (i in 1:nrow(df.s2)) {
subj.name = df.s2$subject[i]
wordlist = (df.words %>% filter(subject == subj.name))$word
c = df.s2$choice[i]
creal = wordlist[amatch(c, wordlist, maxDist = 2)]
cind = getIndex(creal, wordlist)
all_vals = as.numeric.vector(df.s2$all_values[i])
all_vals_rank = rank(all_vals, ties.method = 'max')
s2_val = ifelse(is.na(cind), NA, all_vals[cind])
word_rows = subj.name == df.words$subject & creal == df.words$word
df.s2$choice_real[i] = creal
df.s2$choice_real_ind[i] = cind
df.s2$s2_value[i] = s2_val
df.s2$rank_value[i] = ifelse(is.na(cind), NA, all_vals_rank[cind])
df.s2$s1_value[i] = ifelse(is.na(cind), NA, df.words$value[word_rows])
df.s2$s1_exposures[i] = ifelse(is.na(cind), NA, df.words$exposures[word_rows])
df.s2$high_value[i] = ifelse(type == 1, df.s2$s1_exposures[i] > 8, df.s2$s1_value[i] > 5)
df.s2$high_rank[i] = ifelse(is.na(cind), NA, df.s2$rank_value[i] > 7)
}
df.s2 = df.s2 %>% mutate(s2_subj_ind = as.numeric(as.factor(subject)), # just for modeling
doubled = ifelse(is.na(choice_real_ind), NA, ifelse(is.na(lead(choice_real_ind)), F, choice_real_ind == lead(choice_real_ind)) |
ifelse(is.na(lag(choice_real_ind)), F, choice_real_ind == lag(choice_real_ind))),
bonus_value = ifelse(is.na(choice_real_ind), 0, ifelse(doubled, 0, s2_value)))
df.s2.subj = df.s2 %>% filter(subject %in% df.demo$subject) %>%
group_by(subject) %>%
summarize(s2_bonus = sum(bonus_value), rt = mean(rt) / 1000,
comp_check_pass = mean(comp_check_pass),
comp_check_rt = mean(comp_check_rt) / 1000,
numNAs = sum(is.na(choice_real)),
numRepeats = sum(choice_real == lag(choice_real), na.rm = T),
s1_value = mean(s1_value, na.rm = T),
high_value = mean(high_value, na.rm = T),
rank_value = mean(rank_value, na.rm = T),
high_rank = mean(high_rank, na.rm = T))
df.s2.subj$mem_words = NULL
df.s2.subj$mem_vals = NULL
for (i in 1:nrow(df.s2.subj)) {
s2.filt = df.s2 %>% filter(subject == df.s2.subj$subject[i] & question == 'Memory')
df.s2.subj$mem_words[i] = ifelse(length(s2.filt$choice) == 0, NA, s2.filt$choice)
df.s2.subj$mem_vals[i] = ifelse(length(s2.filt$scratch) == 0, NA, s2.filt$scratch)
}
## Compute recalled
recalled = matrix(F, nrow = nrow(df.s2.subj), ncol = numWords)
recalled_ever = matrix(F, nrow = nrow(df.s2.subj), ncol = numWords)
recalled_val = matrix(F, nrow = nrow(df.s2.subj), ncol = numWords)
df.words$recall = NULL
df.words$recall.ever = NULL
df.words$order = NULL
for (i in 1:nrow(df.s2.subj)) {
subj.name = df.s2.subj$subject[i]
df.words.temp = df.words %>% filter(subject == subj.name)
df.s2.temp = df.s2 %>% filter(subject == subj.name)
words_temp = trimws(as.string.vector(df.s2.subj$mem_words[i]))
val_temp = as.numeric(trimws(as.string.vector(df.s2.subj$mem_vals[i])))
wordlist = df.words.temp$word
if (length(wordlist) == numWords) {
for (j in 1:numWords) {
which_word = amatch(wordlist[j], words_temp, maxDist = 2, nomatch = 0)
recalled[i,j] = which_word > 0
if (recalled[i,j]) {
true_val = df.words.temp$value[df.words.temp$word_ind  == (j - 1)]
recalled_val[i,j] = abs(val_temp[which_word] - true_val) <= 2
}
df.words$recall[df.words$subject == subj.name & df.words$word == wordlist[j]] = recalled[i,j]
recalled_ever[i,j] = recalled[i,j] | any(na.omit(df.s2.temp$choice_real_ind) == j)
df.words$recall.ever[df.words$subject == subj.name & df.words$word == wordlist[j]] = recalled_ever[i,j]
df.words$order[df.words$subject == subj.name & df.words$word == wordlist[j]] = which_word
}
}
}
# exclusion ---------------------------------------------------------------
# Exclude if any of these: cor in s1 < .75, comp_check_pass < .5, pctCorrect_words < .75, pctCorrect_pts < .75, numNAs > 3, numRepeats > 2, numRecalled < 5
include_rows = NULL
include_names = NULL
for (subj in 1:length(subjlist)) {
subj.name = subjlist[subj]
df.s1.subj.temp = df.s1.subj %>% filter(subject == subj.name)
df.s2.subj.temp = df.s2.subj %>% filter(subject == subj.name)
df.demo.temp = df.demo %>% filter(subject == subj.name)
exclude = df.demo.temp$write_down == 'Yes' || df.s2.subj.temp$comp_check_pass < .5 || df.s2.subj.temp$numRepeats > 2 ||
df.s2.subj.temp$numNAs > minNAs || sum(recalled[subj,]) < 5
if (type != 2) {
exclude = exclude || df.s1.subj.temp$numTrials != numTrials || df.s1.subj.temp$pctCorrect_words < .75 ||
df.s1.subj.temp$pctCorrect_val < .75
}
if (exclude) {
include_rows[subj] = FALSE
} else {
include_rows[subj] = TRUE
include_names = c(include_names, subj.name)
}
}
numRealQuestions = 5
df.logit = data.frame(Subj = NULL, Trial = NULL, OptionID = NULL, Choice = NULL, MFval = NULL, MBval = NULL, nExposures = NULL, Recalled = NULL, Question = NULL)
for (subj in 1:nrow(df.demo)) {
subj.name = df.demo$subject[subj]
recalled.temp = recalled_ever[subj, ]
#recalled.temp = !logical(numWords)
num.recalled.temp = sum(recalled.temp)
df.words.temp = df.words %>% filter(subject == subj.name)
df.s2.temp = df.s2 %>% filter(subject == subj.name) %>% arrange(question_order)
nAnswered = sum(!is.na(df.s2.temp$choice_real_ind))
if (nAnswered > 0 & subj.name %in% include_names) {
Subj.col = rep(subj, num.recalled.temp * nAnswered)
MFval.col = rep(df.words.temp$value[recalled.temp], nAnswered)
MFhigh.col = rep(df.words.temp$high_val[recalled.temp] * 1, nAnswered)
nExposures.col = rep(df.words.temp$exposures[recalled.temp], nAnswered)
Recalled.col = rep(df.words.temp$recall.ever[recalled.temp] * 1, nAnswered)
numChosen.col = rep(df.words.temp$numChosen_high[recalled.temp], nAnswered)
#OptionID.col = rep(which(recalled.temp), nAnswered)
OptionID.col = rep(1:num.recalled.temp, nAnswered)
Trial.col = rep(1:nAnswered, each = num.recalled.temp)
Question.col = rep(df.s2.temp$question_ind[!is.na(df.s2.temp$choice_real_ind)], each = num.recalled.temp)
temp.mbval = matrix(0, nrow = nAnswered, ncol = num.recalled.temp)
temp.mbhigh = matrix(0, nrow = nAnswered, ncol = num.recalled.temp)
temp.choice = matrix(0, nrow = nAnswered, ncol = num.recalled.temp)
temp.choice2 = matrix(0, nrow = nAnswered, ncol = num.recalled.temp)
ind = 1
for (q in 1:numRealQuestions) {
if (!is.na(df.s2.temp$choice_real_ind[q])) {
all_vals = as.numeric.vector(df.s2.temp$all_values[q])
mbvals = rank(all_vals, ties.method = 'max')
#mbvals = all_vals
temp.mbval[ind,] = mbvals[recalled.temp]
temp.mbhigh[ind,] = mbvals[recalled.temp] > 13
choice = logical(num.recalled.temp)
choice[which(df.s2.temp$choice_real_ind[q] == which(recalled.temp))] = TRUE
temp.choice[ind,] = choice
#choice2 = vector(mode = 'numeric', num.recalled.temp)
#choice2[1] = which(df.s2.temp$choice_real_ind[q] == which(recalled.temp))
#choice2[1] = OptionID.col[1:num.recalled.temp][choice]
#temp.choice2[ind,] = choice2
ind = ind + 1
}
}
MBval.col = as.vector(t(temp.mbval))
MBhigh.col = as.vector(t(temp.mbhigh))
Choice.col = as.vector(t(temp.choice))
#Choice2.col = as.vector(t(temp.choice2))
df.logit = rbind(df.logit,
data.frame(Subj = Subj.col, Trial = Trial.col, OptionID = OptionID.col, Choice = Choice.col,
MFval = MFval.col, MBval = MBval.col, MFhigh = MFhigh.col, MBhigh = MBhigh.col,
Recall = Recalled.col, Question = Question.col))
}
}
df.sum = df.logit %>% group_by(MFhigh,MBhigh) %>% summarize(Choice.mean = mean(Choice)) #%>% mutate(Choice.mean = Choice.mean * ifelse(MFval %in% c(0,10), 2/3, 1))
ggplot(data = df.sum, aes(x = MBhigh, y = Choice.mean, group = MFhigh, colour = MFhigh)) +
geom_point(aes(size = 2)) + geom_line()
df.sum = df.logit %>% group_by(MFhigh,MBval) %>% summarize(Choice.mean = mean(Choice)) #%>% mutate(Choice.mean = Choice.mean * ifelse(MFval %in% c(0,10), 2/3, 1))
ggplot(data = df.sum, aes(x = MBval, y = Choice.mean, group = MFhigh, colour = MFhigh)) +
geom_point(aes(size = 2)) + geom_line()
## recall
nrecall = rowSums(recalled[include_rows,])
View(df.s2)
View(df.logit)
df.sum = df.logit %>% filter(Question %in% c(4,5)) %>%
group_by(MFhigh,MBval) %>% summarize(Choice.mean = mean(Choice)) #%>% mutate(Choice.mean = Choice.mean * ifelse(MFval %in% c(0,10), 2/3, 1))
ggplot(data = df.sum, aes(x = MBval, y = Choice.mean, group = MFhigh, colour = MFhigh)) +
geom_point(aes(size = 2)) + geom_line()
median(df.logit$MBval)
View(df.logit)
hist(df.logit$MBval)
View(df.logit)
